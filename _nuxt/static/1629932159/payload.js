__NUXT_JSONP__("/", (function(a,b,c,d,e){return {data:[{articleData:{headline:c,summary:"facial recognition",credits:{open:{text:"\u003Cp\u003E\"Erase Your Face\" was produced by YR Media's Interactive team in collaboration with the Stanford d.school's K12 Lab.\u003C\u002Fp\u003E"},close:{text:"\u003Cp\u003EYR Media has joined forces with the \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fappinventor.mit.edu\u002F\" rel=\"nofollow\" target=\"_blank\"\u003EApp Inventor team\u003C\u002Fa\u003E at M.I.T. to make stories, apps and learning resources about A.I. through an equity lens. Stay tuned for \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Finteractive.yr.media\u002Foutsmarting-ai\u002F\" rel=\"nofollow\" target=\"_blank\"\u003Emore\u003C\u002Fa\u003E. We are grateful for support in this work from the National Science Foundation. The opinions, findings, and conclusions or recommendations expressed are those of the makers of Erase Your Face and do not necessarily reflect the views of the NSF.\u003C\u002Fp\u003E"},list:[{k:"Creators",text:"\u003Cp\u003EXion Abiodun, Valeria Araujo, Victoria Balla, Zoe Harwood, Dante Ruberto, Bayani Salgado, Ariel Tang\u003C\u002Fp\u003E"},{k:"Reporters",text:"\u003Cp\u003ENoah Villarreal, Ifalola Amin-McCoy\u003C\u002Fp\u003E"},{k:"Producer",text:"\u003Cp\u003ENimah Gobir\u003C\u002Fp\u003E"},{k:"Designer",text:"\u003Cp\u003EMarjerrie Masicat\u003C\u002Fp\u003E"},{k:"Developer",text:"\u003Cp\u003ERadamés Ajna\u003C\u002Fp\u003E"},{k:"Fellow",text:"\u003Cp\u003EDevin Glover\u003C\u002Fp\u003E"},{k:"Editors",text:"\u003Cp\u003ELissa Soep, Renato Russo, Ariam Mogos\u003C\u002Fp\u003E"},{k:"Special Thanks",text:"\u003Cp\u003E\u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fkylemcdonald.net\u002F\" rel=\"nofollow\" target=\"_blank\"\u003EKyle McDonald\u003C\u002Fa\u003E, \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Flobenichou.com\u002F\" rel=\"nofollow\" target=\"_blank\"\u003ELo Bénichou\u003C\u002Fa\u003E\u003C\u002Fp\u003E"}]},infographic:["Camera detects a face in an image or video.","A photo is captured and analyzed using distinguishable landmarks, like the outside of your eyes or the corner of your lips.","Using these landmarks, the system then aligns the photo to generate a “forward-facing” image of the person.","This “forward-facing” image is converted into a numerical representation of the face.","The numerical representation is then compared against a database of other numerical representations extracted from many other faces until it finds the closest thing to a match."],sections:[{title:b,type:a,text:"\u003Cp\u003EIn the grand scheme of frustrations related to the pandemic, this one's small: you hold your phone up so Face ID can unlock it. You sit there for a few seconds before realizing, oh right, you’ve got a mask on! Your phone doesn't recognize you. \u003C\u002Fp\u003E\n\u003Cp\u003EThe reason? For facial recognition to work, it has to be able to detect what makes your face unique. The technology turns that information into numbers. Yep, hate to break it to you, but each of our lovely faces can be represented through something like a massive spreadsheet filled with digits. Meanwhile, long before you’re sitting there trying in vain to get past your phone’s pesky password screen, \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fweb.archive.org\u002Fweb\u002F20170930030634\u002Fhttps:\u002F\u002Fimages.apple.com\u002Fbusiness\u002Fdocs\u002FFaceID_Security_Guide.pdf\" rel=\"nofollow\" target=\"_blank\"\u003Etech companies\u003C\u002Fa\u003E have already converted millions and millions of other faces into number-sets to create a humongous database for comparison. If your mask blocks enough of your distinctive facial information, even the best algorithms in the world can’t figure out who you are.\u003C\u002Fp\u003E",slug:b},{title:"How Facial Recognition Works",type:"infographic",text:d,slug:"how-facial-recognition-works"},{title:"WISH I WERE HERE",type:a,text:"\u003Cp\u003EHere's the thing, though. Some of us are only now realizing the role that face-tracking apps play in our everyday lives because our features are suddenly hidden behind masks all the time. The state of being \"unseen\" is hardly new for communities that algorithms consistently fail to recognize. The miracle of unlocking digital and sometimes physical doors is operated by algorithms that exhibit bias and inaccuracies \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"http:\u002F\u002Fgendershades.org\u002Foverview.html\" rel=\"nofollow\" target=\"_blank\"\u003Erelative to race and gender.\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EFacial recognition takes various forms ranging from seemingly harmless to dystopically disastrous. Some say technology just automates processes that are already in place, but there’s mounting evidence that recognition systems can heighten existing biases and perpetuate systemic racism.\u003C\u002Fp\u003E\n\u003Cp\u003EHere at YR Media, we’ve been looking into \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fyr.media\u002Ftech\u002Fguide-to-anti-surveillance-fashion\u002F\" rel=\"nofollow\" target=\"_blank\"\u003Ecreative ways to dodge and trick facial detection and surveillance for some time now\u003C\u002Fa\u003E. Using projectors, dramatic make-up and all sorts of other hacks, activists have paved the way with anti-recognition techniques that also make a broader statement about technology in our \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Ftacticaltech.org\u002F#\u002Fabout\" rel=\"nofollow\" target=\"_blank\"\u003Edata-driven world\u003C\u002Fa\u003E. And if you’re looking to just post your selfies in peace, University of Chicago computer engineers are developing a \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fnews.uchicago.edu\u002Fstory\u002Fnew-tool-protect-yourself-against-facial-recognition-software\" rel=\"nofollow\" target=\"_blank\"\u003Etool\u003C\u002Fa\u003E to imperceptibly “cloak” online images from facial recognition systems.\u003C\u002Fp\u003E",slug:"wish-i-were-here"},{title:"Try It Yourself",type:a,text:"\u003Cp\u003EWe wanted to give you a chance to try defying recognition yourself. Using your cursor or finger, select a color and draw over the provided image. Employing a service called Amazon Rekognition, your drawing will be tested against a sea of other \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fgenerated.photos\u002Ffaces\" rel=\"nofollow\" target=\"_blank\"\u003EA.I.-generated faces\u003C\u002Fa\u003E to see if the software can still make a match, despite your attempt to go incognito. Find out how much you need to cover up to hide from those nosy algorithms:\u003C\u002Fp\u003E",slug:"try-it-yourself"},{title:b,type:"Interactive",text:d,slug:b},{title:"HOW IT WORKS",type:a,text:"\u003Cp\u003EIn most cases, Amazon recommends setting its software to \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fdocs.aws.amazon.com\u002Frekognition\u002Flatest\u002Fdg\u002Fcollections.html\" rel=\"nofollow\" target=\"_blank\"\u003Eonly ID photos that yield an 80% match\u003C\u002Fa\u003E, so that’s where we set our cut-off too. If you see multiple matching faces in your results, check out the percentage listed. That’s a “similarity score,” and it shows just how confident the software is that each face is a match. “For many law enforcement use cases, we recommend using a high threshold value of 99% or above to reduce accidental misidentification,” states Amazon Rekognition’s developer guide. And as of June 2020, the company announced a one-year moratorium on police use of their facial recognition technology (more on that below). While these recommendations seem to acknowledge that the technology is fallible, \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.markey.senate.gov\u002Fimo\u002Fmedia\u002Fdoc\u002Facial%20Recognition%20and%20Biometric%20Technology%20Moratorium%20Act.pdf\" rel=\"nofollow\" target=\"_blank\"\u003Eguidelines aren’t consistently enforced\u003C\u002Fa\u003E. Also, keep in mind that when facial recognition technology is implemented at a massive scale — say, if an entire country uses it across their whole population — even tiny changes in confidence can mean the system could very well be identifying the wrong person.\u003C\u002Fp\u003E\n\u003Cp\u003EYou may have noticed we’ve given you pre-uploaded photos to see how much info facial recognition technologies need to work well. That’s because if our goal is to get you thinking critically about facial recognition, the last thing we want is to force you to upload your likeness to get the point!\u003C\u002Fp\u003E",slug:"how-it-works"},{title:"YOU ARE BEING WATCHED",type:a,text:"\u003Cp\u003EThe reality is that these technologies aren’t neutral and neither are the people or institutions that make and use them. \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fyr.media\u002Ftech\u002Fvideo-is-facial-recognition-racist-yes-and-detroit-is-using-it\u002F\" rel=\"nofollow\" target=\"_blank\"\u003ECities allowing facial recognition have been using surveillance systems to monitor and track suspects using mugshots and driver’s license photos\u003C\u002Fa\u003E. In fact, an investigation by the Center on Privacy &amp; Technology at Georgetown Law showed that \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.law.georgetown.edu\u002Fnews\u002Fhalf-of-all-american-adults-are-in-a-police-face-recognition-database-new-report-finds\u002F\" rel=\"nofollow\" target=\"_blank\"\u003Ehalf of American adults are in facial recognition databases that can be accessed by law enforcement agencies. \u003C\u002Fa\u003EAnd with multiple \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fnvlpubs.nist.gov\u002Fnistpubs\u002Fir\u002F2019\u002FNIST.IR.8280.pdf\" rel=\"nofollow\" target=\"_blank\"\u003Estudies\u003C\u002Fa\u003E showing that facial recognition is more likely to misidentify darker-skinned people and only a \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.banfacialrecognition.com\u002Fmap\u002F\" rel=\"nofollow\" target=\"_blank\"\u003Ehandful\u003C\u002Fa\u003E of cities banning use of public surveillance programs, we run the risk of making serious mistakes that disproportionately harm our Black populace.\u003C\u002Fp\u003E\n\u003Cp\u003ERollbacks from tech giants further emphasize the need for accountability and responsibility when using facial recognition technologies. In the wake of Black Lives Matter protests following George Floyd’s murder, even before Amazon announced its moratorium, \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.ibm.com\u002Fblogs\u002Fpolicy\u002Ffacial-recognition-sunset-racial-justice-reforms\u002F\" rel=\"nofollow\" target=\"_blank\"\u003EIBM\u003C\u002Fa\u003E declared that it would “sunset” facial recognition and analysis products. “IBM firmly opposes and will not condone uses of any technology, including facial recognition technology offered by other vendors, for mass surveillance, racial profiling, violations of basic human rights and freedoms, or any purpose which is not consistent with our values,” said IBM CEO Arvind Krishna in an open letter to Congress. \u003C\u002Fp\u003E\n\u003Cp\u003EWe asked \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fliberalarts.utexas.edu\u002Faads\u002Ffaculty\u002Fsb28889\" rel=\"nofollow\" target=\"_blank\"\u003EDr. Simone Browne\u003C\u002Fa\u003E, professor at University of Texas, Austin and author of \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.dukeupress.edu\u002Fdark-matters\" rel=\"nofollow\" target=\"_blank\"\u003EDark Matters: On the Surveillance of Blackness\u003C\u002Fa\u003E, a few of our lingering questions about the state of facial recognition today.\u003C\u002Fp\u003E",slug:"you-are-being-watched"}],interview:{biopicture:"images\u002Fbio_picture.jpg",bookpicture:"images\u002Fbook.jpg",questions:[{question:"What does your work primarily focus on?",response:"I am a researcher, an educator and writer. My research is mainly on surveillance. I approach looking at surveillance, which is quite interdisciplinary, from a Black studies perspective.\nI try to draw some connections between the past and how it can allow us to ask some important questions about our present. And those important questions could be: What are ways that people resist these technologies? What ways were these technologies, ways of identifying people, but also attempting to make people into objects that could be controlled in a particular way? Do we want to be included in these technologies that are often used in very repressive ways? \nA lot of research and development is still under a frame of scientific racism. Those long histories are not behind us. They still inform the social conditions and logics of how these technologies are framed.\nThere are all of these ways that it might be designed to have a certain type of body in mind and that body is often a light body. It's often a male body. It makes certain bodies legible and other parts and pieces of bodies illegible. Gender or race are taken as key ways of identifying people, upholding the idea that gender is binary, which is not the case. Or that race can be quantified. It doesn't recognize many Black people. It recognizes white men at a higher degree."},{question:"What makes facial recognition better than the other security technologies we use?",response:"I guess the question is what do we need to be secure from? Who is the “we”? Who is being policed in particular ways? Who is being jailed or incarcerated? And will facial recognition change that when it's tied to policing? Or will it allow police then to say, “The algorithm was the one that did this, not me”?\nThere are all of these ways of knowing who somebody is, regardless of their face, whether or not it's masked up. What happens when we identify the bag that you have, the shoes that you have, your tattoos? All of these things are part and parcel of policing. Think of all the data that you're putting about yourself from your LinkedIn profile to your Etsy purchases to your Yelp comments to your Facebook. All of that is a parcel of who you are digitally in the world. There are still ways in which we are captured by the things we do that might be beyond facial recognition technology, but other types of biometrics that are tied in with the digital data footprint we leave in the online world."},{question:"Who gains from using facial recognition technologies?",response:"Through popular culture, people develop a certain type of consent to these technologies because they seem to make our lives a bit easier. And for some people, there’s the idea that they're always under threat, always in need of protection and that surveillance technology will save them. That's an easy tradeoff to say, “Sure, I'm going to have this Ring doorbell because I want to be nosy, but also I'm okay with the police having access to it at all times or Amazon selling that data.”"},{question:"We’re starting to see companies like IBM and Amazon put limits around how facial recognition technologies are being used. What do you make of this?",response:"I think those are important steps. \nWe have to understand the past of this company to be a bit skeptical of their pauses. And for me, it's like, “OK, they're pausing now. What are they working on?” Amazon and IBM are not going to stop being capitalists. They are not just going to stop making money.\nI think this pause points to a lot of work that's being done by activists, by artists, by researchers, by educators, by people that have been really pushing back at the municipal level to abolish these technologies. So, while there is this pause, the pressure has to stay on."}]}},postData:{baseURL:"\u002Ferase-your-face",title:c,author:"YR Media's Interactive Team with Stanford d.school",publishDate:"October 20, 2020",location:"Oakland, CA",description:e,summary:e,tweetMessage:"with @itsyrmedia and @stanforddschool",url:"https:\u002F\u002Fyouthradio.github.io\u002Ferase-your-face",featureImage:"https:\u002F\u002Fyouthradio.github.io\u002Ferase-your-face\u002Fimages\u002Fsocial.jpg",featureImagePath:"images\u002Ffeature-image",featureImageDescription:"Woman looking at kiosk.",featureImageCaption:"",wpPostSlug:"north-carolina-vs-vaping-companies",wpPostID:"60986",fbAppID:"73080818131",twitterHandler:"@itsyrmedia",docs:[{name:"Erase Your Face draft FINAL - backend data",id:"1rRMPbN6Y7y04fmKlHf6lXIPkp1mx9c8FBPxeC3XlZYI"}],dataPath:"data\u002Fdata.json",lambdaAppURL:"https:\u002F\u002F53fj52a3ud.execute-api.us-west-2.amazonaws.com\u002Flatest\u002F"}}],fetch:{},mutations:[["LOAD_STORE",void 0]]}}("text","null","Erase Your Face","\u003Cp\u003Enull\u003C\u002Fp\u003E","Ever get the prickly feeling that you’re being watched? You’re probably right. Biased facial recognition and surveillance technologies are everywhere, so we created a tool to help you learn what it takes to dodge detection.")));