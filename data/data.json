{"content":[{"headline":"Erase Your Face","summary":"facial recognition","credits":{"text":"","Credits":"","Reporters":"Xion Abiodun, Valeria Araujo, Victoria Balla, Zoe Harwood, Dante Ruberto,, Bayani Salgado, Ariel Tang, and Stanford D-school youth]","Producer":"Nimah Gobir","Designer":"Marjerrie Masicat","Developer":"Radamés Ajna","Fellow":"Devin Glover","Editors":"Lissa Soep, Renato Russo, Ariam Mogos"},"infographic":["Camera detects a face in an image or video.","A photo is captured and analyzed using distinguishable landmarks as references. These landmarks can include a person’s nose size, distance between eyes, and face shape.","This facial analysis is then converted into code.","This code is compared against a database until a match is found."],"sections":[{"title":"null","type":"text","text":"<p>In the grand scheme of frustrations related to the pandemic, this one's small: you hold your phone up so Face ID can unlock it. You sit there for a few seconds before realizing, oh right, you’ve got a mask on! Your phone doesn't know who you are. </p>\n<p>The reason? Facial recognition relies on the software's ability to identify distinguishing physical characteristics, like the space between your eyes or width of your nose, and cross-check that data against billions of photos your device has been \"trained\" to classify. Artificial intelligence is what makes it all possible. The machine is performing a task like humans do, learning as it goes, but based on way more information than any person could handle.</p>","slug":"null"},{"title":"infographic","type":"infographic","text":"<p>null</p>","slug":"infographic"},{"title":"WISH I WERE HERE","type":"text","text":"<p>Here's the thing, though. Some of us are only now realizing the role that face-tracking apps play in our everyday lives because our features are suddenly hidden behind masks all the time. TBut the state of being \"unseen\" is hardly new for communities that algorithms consistently fail to recognize. The miracle of unlocking digital and sometimes physical doors is operated by algorithms that exhibit bias and inaccuracies <a class=\"link blue underline underline-hover hover-dark-red\" href=\"http://gendershades.org/overview.html\" rel=\"nofollow\" target=\"_blank\">relative to race and gender.</a></p>\n<p>Facial recognition takes various forms ranging from seemingly harmless to dystopically disastrous. Under the guise of tech neutrality, an argument implying that technology is just a way of optimizing processes that are already in place, these technologies can heightenreproduce already existing biases and perpetuate systemic racism.</p>\n<p>Here at YR Media, wWe’ve been looking into <a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://yr.media/tech/guide-to-anti-surveillance-fashion/\" rel=\"nofollow\" target=\"_blank\">creative ways to dodge and trick facial recognition and surveillance for some time now</a>. From projectors to dramatic make-up, activists have paved the way with successful anti-recognition techniques that also make a broader statement about technology in our data-driven world. </p>\n<p>We wanted to give you a chance to try it out for yourself. Using your cursor or finger, select a color and begin to draw draw over the provided image. Employing Amazon Rekognition’s technology, your drawing will be tested against a sea of other A.I.- generated faces to see if the software can still make a match, despite your attempt to go incognito. from Generated Photos. Find out how much you need to cover up to hide from thosebe unrecognizable to nosy algorithms:</p>","slug":"wish-i-were-here"},{"title":"Interactive","type":"Interactive","text":"<p>null</p>","slug":"interactive"},{"title":"HOW IT WORKS","type":"text","text":"<p>Our handy tool relies on aAmazon’s facial recognition service called Amazon Rekognition. In most cases, the companythey recommends setting itstheir software to <a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://docs.aws.amazon.com/rekognition/latest/dg/collections.html\" rel=\"nofollow\" target=\"_blank\">only ID photos that yield an 80% match</a><a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://docs.aws.amazon.com/rekognition/latest/dg/collections.html\" rel=\"nofollow\" target=\"_blank\">, so that’s where we set our cut-off too</a>. “For many law enforcement use cases, we recommend using a high threshold value of 99% or above to reduce accidental misidentification,” states Amazon Rekognition’s developer guide. </p>\n<p>While theseir recommendations seem to acknowledge that the technology is n’t infallible, the guidelines they outline aren’t enforced. [NOTE: You may have noticed we’ve given you pre-uploaded photos to see how much info facial recognition technologies need to work well. That’s because we don’t want to encourage you to add images of your likenessface to the growing database of faces accessible to those using facial recognition services].</p>","slug":"how-it-works"},{"title":"YOU ARE BEING WATCHED","type":"text","text":"<p>The reality is that these technologies aren’t neutral and neither are the people or institutions that make andchoose to use them. <a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://yr.media/tech/video-is-facial-recognition-racist-yes-and-detroit-is-using-it/\" rel=\"nofollow\" target=\"_blank\">Cities allowing facial recognition have been using surveillance systems to monitor and track suspected criminals using mugshots and driver</a><a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://yr.media/tech/video-is-facial-recognition-racist-yes-and-detroit-is-using-it/\" rel=\"nofollow\" target=\"_blank\">’</a><a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://yr.media/tech/video-is-facial-recognition-racist-yes-and-detroit-is-using-it/\" rel=\"nofollow\" target=\"_blank\">s license photos</a>. In fact, an investigation by the Center on Privacy &amp; Technology at Georgetown Law showed that <a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://www.law.georgetown.edu/news/half-of-all-american-adults-are-in-a-police-face-recognition-database-new-report-finds/\" rel=\"nofollow\" target=\"_blank\">half of American </a><a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://www.law.georgetown.edu/news/half-of-all-american-adults-are-in-a-police-face-recognition-database-new-report-finds/\" rel=\"nofollow\" target=\"_blank\">a</a><a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://www.law.georgetown.edu/news/half-of-all-american-adults-are-in-a-police-face-recognition-database-new-report-finds/\" rel=\"nofollow\" target=\"_blank\">A</a><a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://www.law.georgetown.edu/news/half-of-all-american-adults-are-in-a-police-face-recognition-database-new-report-finds/\" rel=\"nofollow\" target=\"_blank\">dults are in facial recognition databases that can be accessed by law enforcement agencies. </a>And with multiple studies showing that facial recognition is more likely to misidentify darker-skinned people and only four cities that have banned use of public surveillance programs, we run the risk of making serious mistakes that disproportionately harm our black populace.</p>\n<p>Rollbacks from tech giants IBM and Amazon further emphasize the need for accountability and responsibility when using facial recognition technologies. In the wake of Black Lives Matter protests following George Floyd’s murder, <a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://www.ibm.com/blogs/policy/facial-recognition-sunset-racial-justice-reforms/\" rel=\"nofollow\" target=\"_blank\">IBM</a> stopped offering itstheir facial recognition and analysis products. “IBM firmly opposes and will not condone uses of any technology, including facial recognition technology offered by other vendors, for mass surveillance, racial profiling, violations of basic human rights and freedoms, or any purpose which is not consistent with our values,” said IBM CEO Arvind Krishna in an open letter to Congress. Shortly after, <a class=\"link blue underline underline-hover hover-dark-red\" href=\"https://blog.aboutamazon.com/policy/we-are-implementing-a-one-year-moratorium-on-police-use-of-rekognition\" rel=\"nofollow\" target=\"_blank\">Amazon</a> announced a one year moratorium on police use of their facial recognition technology. </p>\n<p>We askedhad Dr. Simone Browne, professor at University of Texas, Austin, and author of Dark Matters: On the Surveillance of Blackness, answer a few of our lingering questions about the state of facial recognition today.</p>","slug":"you-are-being-watched"}],"interview":{"biopicture":"images/bio_picture.jpg","bookpicture":"images/book.jpg","questions":[{"question":"What does your work primarily focus on?","response":"I am a researcher, an educator and writer. My research is mainly on surveillance. I approach looking at surveillance, which is quite interdisciplinary, from a black studies perspective.\nI try to draw some connections between the past and how it can allow us to ask some important questions about our present. And those important questions could be: What are ways that people resist these technologies? What ways were these technologies, ways of identifying people, but also attempting to make people into objects that could be controlled in a particular way? Do we want to be included in these technologies that are often used in very repressive ways? \nA lot of research and development is still under a frame of scientific racism. Those long histories are not behind us. They still form the social conditions and intellectual logics of how these technologies are framed.\nThere are all of these ways that it might be designed to have a certain type of body in mind and that body is often a light body. It's often a male body. It makes certain bodies legible and other parts and pieces of bodies illegible. Gender or race are key ways of identifying people. It doesn't recognize black people. It recognizes white men at a higher degree."},{"question":"What makes facial recognition better than the other security technologies we use?","response":"I guess the question is what do we need to be secure from? Who is the “we” and what can we do better? Who is being policed in particular ways? Who is being jailed or incarcerated? And will facial recognition change that when it's tied to policing? Or will it allow police then to say’ “The algorithm was the one that did this, not me.”?\nThere are all of these ways of knowing who somebody is, regardless of their face, whether or not it's masked up. What happens when we identify the bag that you have, the shoes that you have, your tattoos? All of these things are part and parcel of policing. Think of all the data that you're putting about yourself from your LinkedIn profile to your Etsy purchases to your Yelp comments to your Facebook. All of that is a parcel of who you are digitally in the world. There are still ways in which we are captured by the things we do that might be beyond facial recognition technology, but other types of biometrics that are tied in with the digital data footprint we leave in the online world."},{"question":"Who gains from using facial recognition technologies?","response":"Through popular culture, people develop a certain type of consent to these technologies because they seem to make our lives a bit easier. And for some people, there’s the idea that they're always under threat, always in need of protection and that surveillance technology will save them. That's an easy tradeoff to say, ‘Sure, I'm going to have this Ring doorbell because I want to be nosy, but also I'm okay with the police having access to it at all times or Amazon selling that data."},{"question":"We’re starting to see companies like IBM and Amazon put limits around how facial recognition technologies are being used. What do you make of this?","response":"I think those are important steps. \nWe have to understand the past of this company to be a bit skeptical of their pauses. And for me, it's like, “OK, they're pausing now. What are they working on?” Amazon and IBM are not going to stop being capitalists. They are not just going to stop making money.\nI think this pause points to a lot of work that's being done by activists, by artists, by researchers, by educators, by people that have been really pushing back in cities, at the municipal level to abolish these technologies. So, while there is this pause, the pressure has to stay on."}]}}]}